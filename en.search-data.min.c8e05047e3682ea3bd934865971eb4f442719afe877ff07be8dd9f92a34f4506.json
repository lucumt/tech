[{"id":0,"href":"/docs/monitor/top-9-cases-behind-cpu-high-usage/","title":"CPUä½¿ç”¨è¾¾åˆ°100%çš„9ä¸ªåœºæ™¯","section":"è¿ç»´","content":"\n"},{"id":1,"href":"/docs/db/es/top-6-es-use-cases/","title":"ESä½¿ç”¨æœ€é«˜çš„6ä¸ªåœºæ™¯","section":"ElasticSearch","content":"\nTop 6 ElasticSearch Use Cases. . . Elasticsearch is widely used for its powerful and versatile search capabilities. The diagram below shows the top 6 use cases:\nğŸ”¹ Full-Text Search Elasticsearch excels in full-text search scenarios due to its robust, scalable, and fast search capabilities. It allows users to perform complex queries with near real-time responses.\nğŸ”¹ Real-Time Analytics Elasticsearch\u0026rsquo;s ability to perform analytics in real-time makes it suitable for dashboards that track live data, such as user activity, transactions, or sensor outputs.\nğŸ”¹ Machine Learning With the addition of the machine learning feature in X-Pack, Elasticsearch can automatically detect anomalies, patterns, and trends in the data.\nğŸ”¹ Geo-Data Applications Elasticsearch supports geo-data through geospatial indexing and searching capabilities. This is useful for applications that need to manage and visualize geographical information, such as mapping and location-based services.\nğŸ”¹ Log and Event Data Analysis Organizations use Elasticsearch to aggregate, monitor, and analyze logs and event data from various sources. It\u0026rsquo;s a key component of the ELK stack (Elasticsearch, Logstash, Kibana), which is popular for managing system and application logs to identify issues and monitor system health.\nğŸ”¹ Security Information and Event Management (SIEM) Elasticsearch can be used as a tool for SIEM, helping organizations to analyze security events in real time.\n"},{"id":2,"href":"/docs/code/front/how-does-javascript-work/","title":"JavaScriptæ˜¯å¦‚ä½•æ‰§è¡Œçš„","section":"å‰ç«¯","content":"\nThe cheat sheet below shows most important characteristics of Javascript.\nğŸ”¹ Interpreted Language JavaScript code is executed by the browser or JavaScript engine rather than being compiled into machine language beforehand. This makes it highly portable across different platforms. Modern engines such as V8 utilize Just-In-Time (JIT) technology to compile code into directly executable machine code.\nğŸ”¹ Function is First-Class Citizen In JavaScript, functions are treated as first-class citizens, meaning they can be stored in variables, passed as arguments to other functions, and returned from functions.\nğŸ”¹ Dynamic Typing JavaScript is a loosely typed or dynamic language, meaning we don\u0026rsquo;t have to declare a variable\u0026rsquo;s type ahead of time, and the type can change at runtime.\nğŸ”¹ Client-Side Execution JavaScript supports asynchronous programming, allowing operations like reading files, making HTTP requests, or querying databases to run in the background and trigger callbacks or promises when complete. This is particularly useful in web development for improving performance and user experience.\nğŸ”¹ Prototype-Based OOP Unlike class-based object-oriented languages, JavaScript uses prototypes for inheritance. This means that objects can inherit properties and methods from other objects.\nğŸ”¹ Automatic Garbage Collection Garbage collection in JavaScript is a form of automatic memory management. The primary goal of garbage collection is to reclaim memory occupied by objects that are no longer in use by the program, which helps prevent memory leaks and optimizes the performance of the application.\nğŸ”¹ Compared with Other Languages JavaScript is special compared to programming languages like Python or Java because of its position as a major language for web development.\nWhile Python is known to provide good code readability and versatility, and Java is known for its structure and robustness, JavaScript is an interpreted language that runs directly on the browser without compilation, emphasizing flexibility and dynamism.\nğŸ”¹ Relationship with Typescript TypeScript is a superset of JavaScript, which means that it extends JavaScript by adding features to the language, most notably type annotations. This relationship allows any valid JavaScript code to also be considered valid TypeScript code.\nğŸ”¹ Popular Javascript Frameworks React is known for its flexibility and large number of community-driven plugins, while Vue is clean and intuitive with highly integrated and responsive features. Angular, on the other hand, offers a strict set of development specifications for enterprise-level JS development.\n"},{"id":3,"href":"/docs/code/mq/top-5-kafka-use-cases/","title":"Kafkaçš„5ç§ä½¿ç”¨åœºæ™¯","section":"æ¶ˆæ¯ä¸­é—´ä»¶","content":"\n"},{"id":4,"href":"/docs/code/block/mysql-batch-create-data/","title":"MySQLæ‰¹é‡åˆ¶é€ æ•°æ®","section":"ä»£ç å—","content":"åˆ©ç”¨mysqlçš„å­˜å‚¨è¿‡ç¨‹å¿«é€Ÿæ’å…¥å¤§é‡æ•°æ®\n1DELIMITER $$ 2 3USE `test`$$ 4 5DROP PROCEDURE IF EXISTS `add_user_batch`$$ 6 7CREATE DEFINER=`root`@`%` PROCEDURE `add_user_batch`(IN COUNT INT) 8BEGIN 9 DECLARE i INT; 10 DECLARE t_name VARCHAR(8); 11 DECLARE t_tag VARCHAR(20); 12 DECLARE t_age INT(2); 13 DECLARE t_sql_template VARCHAR(100); 14 DECLARE t_sql TEXT; 15 DECLARE t_tag_mod_val INT DEFAULT(25); 16 DECLARE t_commit_mod_val INT DEFAULT(100); 17 18 DECLARE t_start_time DATETIME; 19 DECLARE t_end_time DATETIME; 20 21 TRUNCATE TABLE `system_user`; 22 23 SET t_start_time=NOW(); 24 SET t_sql_template = \u0026#34;INSERT INTO `system_user`(NAME, age, tag) VALUES\u0026#34;; 25 SET t_sql = t_sql_template; 26 SET i = 1; 27 WHILE i \u0026lt;= COUNT 28 DO 29 SET t_age = FLOOR(1 + RAND() * 60); 30 SET t_name = LEFT(UUID(), 8); 31 -- ç»™tagéšæœºåˆ¶é€ ç©ºå€¼ 32 IF MOD(i, t_tag_mod_val) = 0 THEN 33 SET t_tag = \u0026#34;NULL\u0026#34;; 34 ELSE 35 SET t_tag = CONCAT(\u0026#34;\u0026#39;\u0026#34;,LEFT(UUID(), 8),\u0026#34;\u0026#39;\u0026#34;); 36 END IF; 37 38 SET t_sql = CONCAT(t_sql,\u0026#34;(\u0026#39;\u0026#34;,t_name,\u0026#34;\u0026#39;,\u0026#34;,t_age,\u0026#34;,\u0026#34;,t_tag,\u0026#34;)\u0026#34;); 39 40 IF MOD(i,t_commit_mod_val) != 0 THEN 41 SET t_sql = CONCAT(t_sql,\u0026#34;,\u0026#34;); 42 ELSE 43 SET t_sql = CONCAT(t_sql,\u0026#34;;\u0026#34;); 44 -- åªè¦è¾¾åˆ°t_commit_mod_valè¦æ±‚çš„æ¬¡æ•°ï¼Œå°±æ‰§è¡Œå¹¶æäº¤ 45 SET @insert_sql = t_sql; 46 PREPARE stmt FROM @insert_sql; 47 EXECUTE stmt; 48 DEALLOCATE PREPARE stmt; 49 COMMIT; 50 SET t_sql=t_sql_template; 51 END IF; 52 SET i = i + 1; 53 END WHILE; 54 55 -- ä¸èƒ½è¢«t_commit_mod_valæ•´é™¤æ—¶ï¼Œä½™ä¸‹çš„æ•°æ®å¤„ç† 56 IF LENGTH(t_sql) \u0026gt; LENGTH(t_sql_template) THEN 57 SET t_sql=CONCAT(SUBSTRING(t_sql,1,LENGTH(t_sql)-1),\u0026#39;;\u0026#39;); 58 SET @insert_sql = t_sql; 59 PREPARE stmt FROM @insert_sql; 60 EXECUTE stmt; 61 DEALLOCATE PREPARE stmt; 62 COMMIT; 63 END IF; 64 SET t_end_time=NOW(); 65 SELECT CONCAT(\u0026#39;insert data success,time cost \u0026#39;,TIMEDIFF(t_end_time,t_start_time)) AS finishedTag; 66END$$ 67 68DELIMITER ; "},{"id":5,"href":"/docs/other/stop-the-war/","title":"Stop The War","section":"å…¶å®ƒ","content":"\n"},{"id":6,"href":"/docs/network/tcp-status-change/","title":"TCPçŠ¶æ€å˜åŒ–å›¾","section":"ç½‘ç»œ","content":"\n"},{"id":7,"href":"/docs/security/identity-manage-types/","title":"ä¸åŒçš„èº«ä»½ç®¡ç†æ–¹å¼","section":"å®‰å…¨","content":"\n"},{"id":8,"href":"/docs/security/authentication-types-compare/","title":"ä¸åŒè®¤è¯æ–¹å¼çš„å¯¹æ¯”","section":"å®‰å…¨","content":"\n"},{"id":9,"href":"/docs/code/theory/language-compare/","title":"ä¸åŒè¯­è¨€çš„å·¥ä½œåŸç†","section":"ç†è®º","content":"\nHow Do C++, Java, Python Work?\nThe diagram shows how the compilation and execution work.\nCompiled languages are compiled into machine code by the compiler. The machine code can later be executed directly by the CPU. Examples: C, C++, Go.\nA bytecode language like Java, compiles the source code into bytecode first, then the JVM executes the program. Sometimes JIT (Just-In-Time) compiler compiles the source code into machine code to speed up the execution. Examples: Java, C#\nInterpreted languages are not compiled. They are interpreted by the interpreter during runtime. Examples: Python, Javascript, Ruby\nCompiled languages in general run faster than interpreted languages.\n"},{"id":10,"href":"/docs/cloud/cloud-tech-stack/","title":"äº‘åŸç”ŸæŠ€æœ¯æ ˆ","section":"äº‘åŸç”Ÿ","content":"\n"},{"id":11,"href":"/docs/db/theory/8-key-data-structures-that-power-modern-databases/","title":"æ•°æ®åº“ä¸­çš„8ä¸ªå…³é”®æ•°æ®ç»“æ„","section":"ç†è®º","content":"\n8 Key Data Structures That Power Modern Databases ğŸ”¹Skiplist: a common in-memory index type. Used in Redis ğŸ”¹Hash index: a very common implementation of the â€œMapâ€ data structure (or â€œCollectionâ€) ğŸ”¹SSTable: immutable on-disk â€œMapâ€ implementation ğŸ”¹LSM tree: Skiplist + SSTable. High write throughput ğŸ”¹B-tree: disk-based solution. Consistent read/write performance ğŸ”¹Inverted index: used for document indexing. Used in Lucene ğŸ”¹Suffix tree: for string pattern search ğŸ”¹R-tree: multi-dimension search, such as finding the nearest neighbor\n"},{"id":12,"href":"/docs/linux/system/linux-file-system/","title":"æ–‡ä»¶ç±»å‹è¯´æ˜","section":"Linuxç³»ç»Ÿ","content":"\nThe Linux file system used to resemble an unorganized town where individuals constructed their houses wherever they pleased. However, in 1994, the Filesystem Hierarchy Standard (FHS) was introduced to bring order to the Linux file system.\nBy implementing a standard like the FHS, software can ensure a consistent layout across various Linux distributions. Nonetheless, not all Linux distributions strictly adhere to this standard. They often incorporate their own unique elements or cater to specific requirements.\nTo become proficient in this standard, you can begin by exploring. Utilize commands such as \u0026ldquo;cd\u0026rdquo; for navigation and \u0026ldquo;ls\u0026rdquo; for listing directory contents. Imagine the file system as a tree, starting from the root (/). With time, it will become second nature to you, transforming you into a skilled Linux administrator.\n"},{"id":13,"href":"/docs/test/test-method-compare/","title":"æµ‹è¯•æ–¹æ³•å¯¹æ¯”","section":"æµ‹è¯•","content":"\n"},{"id":14,"href":"/docs/code/java/thread-lifecycle/","title":"çº¿ç¨‹ç”Ÿå‘½å‘¨æœŸè¯´æ˜","section":"java","content":" å›¾è§£1 # å›¾è§£2 # "},{"id":15,"href":"/docs/microservice/develop/what-does-api-gateway-do/","title":"ç½‘å…³çš„ä½œç”¨","section":"å¾®æœåŠ¡å¼€å‘","content":"\n"},{"id":16,"href":"/docs/cloud/top-6-clould-message-patterns/","title":"6ç§äº‘æ¶ˆæ¯ä¼ é€’æ¨¡å¼","section":"äº‘åŸç”Ÿ","content":"\nHow do services communicate with each other? The diagram below shows 6 cloud messaging patterns.\nğŸ”¹ Asynchronous Request-Reply\nThis pattern aims at providing determinism for long-running backend tasks. It decouples backend processing from frontend clients.\nIn the diagram below, the client makes a synchronous call to the API, triggering a long-running operation on the backend. The API returns an HTTP 202 (Accepted) status code, acknowledging that the request has been received for processing.\nğŸ”¹ Publisher-Subscriber\nThis pattern targets decoupling senders from consumers, and avoiding blocking the sender to wait for a response.\nğŸ”¹ Claim Check\nThis pattern solves the transmision of large messages. It stores the whole message payload into a database and transmits only the reference to the message, which will be used later to retrieve the payload from the database.\nğŸ”¹ Priority Queue\nThis pattern prioritizes requests sent to services so that requests with a higher priority are received and processed more quickly than those with a lower priority.\nğŸ”¹ Saga\nSaga is used to manage data consistency across multiple services in distributed systems, especially in microservices architectures where each service manages its own database.\nThe saga pattern addresses the challenge of maintaining data consistency without relying on distributed transactions, which are difficult to scale and can negatively impact system performance.\nğŸ”¹ Competing Consumers\nThis pattern enables multiple concurrent consumers to process messages received on the same messaging channel. There is no need to configure complex coordination between the consumers. However, this pattern cannot guarantee message ordering.\n"},{"id":17,"href":"/docs/test/9-types-api-testing/","title":"9ä¸­APIæµ‹è¯•æ–¹å¼","section":"æµ‹è¯•","content":"\nExplaining 9 types of API testing.\nğŸ”¹ Smoke Testing This is done after API development is complete. Simply validate if the APIs are working and nothing breaks.\nğŸ”¹ Functional Testing This creates a test plan based on the functional requirements and compares the results with the expected results.\nğŸ”¹ Integration Testing This test combines several API calls to perform end-to-end tests. The intra-service communications and data transmissions are tested.\nğŸ”¹ Regression Testing This test ensures that bug fixes or new features shouldnâ€™t break the existing behaviors of APIs.\nğŸ”¹ Load Testing This tests applicationsâ€™ performance by simulating different loads. Then we can calculate the capacity of the application.\nğŸ”¹ Stress Testing We deliberately create high loads to the APIs and test if the APIs are able to function normally.\nğŸ”¹ Security Testing This tests the APIs against all possible external threats.\nğŸ”¹ UI Testing This tests the UI interactions with the APIs to make sure the data can be displayed properly.\nğŸ”¹ Fuzz Testing This injects invalid or unexpected input data into the API and tries to crash the API. In this way, it identifies the API vulnerabilities.\n"},{"id":18,"href":"/docs/network/http-status/","title":"HTTPçŠ¶æ€ç è¯´æ˜","section":"ç½‘ç»œ","content":"\n"},{"id":19,"href":"/docs/code/mq/can-kafka-lose-messages/","title":"kakfaä¸¢å¤±æ¶ˆæ¯çš„åœºæ™¯","section":"æ¶ˆæ¯ä¸­é—´ä»¶","content":"\nError handling is one of the most important aspects of building reliable systems.\nToday, we will discuss an important topic: Can Kafka lose messages?\nA common belief among many developers is that Kafka, by its very design, guarantees no message loss. However, understanding the nuances of Kafka\u0026rsquo;s architecture and configuration is essential to truly grasp how and when it might lose messages, and more importantly, how to prevent such scenarios.\nThe diagram below shows how a message can be lost during its lifecycle in Kafka.\nğŸ”¹ Producer When we call producer.send() to send a message, it doesn\u0026rsquo;t get sent to the broker directly. There are two threads and a queue involved in the message-sending process:\n\\1. Application thread \\2. Record accumulator \\3. Sender thread (I/O thread)\nWe need to configure proper â€˜acksâ€™ and â€˜retriesâ€™ for the producer to make sure messages are sent to the broker.\nğŸ”¹ Broker A broker cluster should not lose messages when it is functioning normally. However, we need to understand which extreme situations might lead to message loss:\n\\1. The messages are usually flushed to the disk asynchronously for higher I/O throughput, so if the instance is down before the flush happens, the messages are lost.\n\\2. The replicas in the Kafka cluster need to be properly configured to hold a valid copy of the data. The determinism in data synchronization is important.\nğŸ”¹ Consumer Kafka offers different ways to commit messages. Auto-committing might acknowledge the processing of records before they are actually processed. When the consumer is down in the middle of processing, some records may never be processed.\nA good practice is to combine both synchronous and asynchronous commits, where we use asynchronous commits in the processing loop for higher throughput and synchronous commits in exception handling to make sure the the last offset is always committed.\n"},{"id":20,"href":"/docs/code/block/matplotlib-show-chinese/","title":"Matplotlibå±•ç¤ºä¸­æ–‡","section":"ä»£ç å—","content":"åœ¨Matplotlibä¸­å±•ç¤ºä¸­æ–‡ï¼Œé˜²æ­¢ä¹±ç \næ ¸å¿ƒä»£ç ï¼š\n1plt.rcParams[\u0026#39;font.sans-serif\u0026#39;]=[\u0026#39;SimHei\u0026#39;] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾ 2plt.rcParams[\u0026#39;axes.unicode_minus\u0026#39;] = False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå· å®Œæ•´ä»£ç ï¼š\n1import numpy as np 2import matplotlib.pyplot as plt 3from sklearn.linear_model import Lasso 4 5plt.rcParams[\u0026#39;font.sans-serif\u0026#39;]=[\u0026#39;SimHei\u0026#39;] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾ 6plt.rcParams[\u0026#39;axes.unicode_minus\u0026#39;] = False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå· 7 8# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® 9np.random.seed(42) 10disciple_count = np.random.randint(50, 200, size=20) 11establishment_years = np.random.randint(1, 100, size=20) 12weapon_types = np.random.randint(1, 10, size=20) 13master_skill = 2 * disciple_count + 1.5 * establishment_years + 3 * weapon_types + np.random.randn(20) * 20 + 100 14 15# æ•°æ®è½¬æ¢ä¸ºäºŒç»´æ•°ç»„ 16X = np.column_stack((disciple_count, establishment_years, weapon_types)) 17y = master_skill 18 19# åˆ›å»ºLassoå›å½’æ¨¡å‹å¹¶è®­ç»ƒ 20lasso_reg = Lasso(alpha=0.1) 21lasso_reg.fit(X, y) 22 23# æ‰“å°æ¨¡å‹å‚æ•° 24print(\u0026#34;æˆªè·:\u0026#34;, lasso_reg.intercept_) 25print(\u0026#34;ç³»æ•°:\u0026#34;, lasso_reg.coef_) 26 27# å¯è§†åŒ–å›å½’å¹³é¢ï¼ˆè¿™é‡Œåªèƒ½å±•ç¤ºä¸¤ä¸ªç‰¹å¾çš„äºŒç»´å¹³é¢å›¾ï¼‰ 28plt.scatter(disciple_count, master_skill, color=\u0026#39;blue\u0026#39;, label=\u0026#39;å®é™…æ•°æ®\u0026#39;) 29plt.plot(disciple_count, lasso_reg.intercept_ + lasso_reg.coef_[0] * disciple_count + lasso_reg.coef_[1] * np.mean(establishment_years), color=\u0026#39;red\u0026#39;, linewidth=2, label=\u0026#39;å›å½’ç›´çº¿\u0026#39;) 30plt.title(\u0026#34;æ­¦ä¾ å°è¯´ä¸­çš„Lassoå›å½’ç¤ºä¾‹\u0026#34;) 31plt.xlabel(\u0026#34;å¼Ÿå­æ•°é‡\u0026#34;) 32plt.ylabel(\u0026#34;æŒé—¨æ­¦åŠŸä¿®ä¸º\u0026#34;) 33plt.legend() 34plt.show() "},{"id":21,"href":"/docs/other/how-visa-make-money/","title":"Visaæ˜¯å¦‚ä½•æŒ£é’±çš„","section":"å…¶å®ƒ","content":"\nWhy is the credit card called â€œğ­ğ¡ğ ğ¦ğ¨ğ¬ğ­ ğ©ğ«ğ¨ğŸğ¢ğ­ğšğ›ğ¥ğ product in banksâ€? How does VISA/Mastercard make money?\nThe diagram below shows the economics of the credit card payment flow.\nThe cardholder pays a merchant $100 to buy a product.\nThe merchant benefits from the use of the credit card with higher sales volume, and needs to compensate the issuer and the card network for providing the payment service. The acquiring bank sets a fee with the merchant, called the â€œğ¦ğğ«ğœğ¡ğšğ§ğ­ ğğ¢ğ¬ğœğ¨ğ®ğ§ğ­ ğŸğğ.â€\n3 - 4. The acquiring bank keeps $0.25 as the ğšğœğªğ®ğ¢ğ«ğ¢ğ§ğ  ğ¦ğšğ«ğ¤ğ®ğ©, and $1.75 is paid to the issuing bank as the ğ¢ğ§ğ­ğğ«ğœğ¡ğšğ§ğ ğ ğŸğğ. The merchant discount fee should cover the interchange fee.\nThe interchange fee is set by the card network because it is less efficient for each issuing bank to negotiate fees with each merchant.\nThe card network sets up the ğ§ğğ­ğ°ğ¨ğ«ğ¤ ğšğ¬ğ¬ğğ¬ğ¬ğ¦ğğ§ğ­ğ¬ ğšğ§ğ ğŸğğğ¬ with each bank, which pays the card network for its services every month. For example, VISA charges a 0.11% assessment, plus a $0.0195 usage fee, for every swipe.\nThe cardholder pays the issuing bank for its services.\nWhy should the issuing bank be compensated? ğŸ”¹The issuer pays the merchant even if the cardholder fails to pay the issuer. ğŸ”¹The issuer pays the merchant before the cardholder pays the issuer. ğŸ”¹The issuer has other operating costs, including managing customer accounts, providing statements, fraud detection, risk management, clearing \u0026amp; settlement, etc.\nOver to you: Does the card network charge the same interchange fee for big merchants as for small merchants?\n"},{"id":22,"href":"/docs/code/theory/concurrency-is-not-parallelism/","title":"å¹¶å‘ä¸æ˜¯å¹¶è¡Œ","section":"ç†è®º","content":"\nThings Every Developer Should Know: Concurrency is ğğğ“ parallelism.\nIn system design, it is important to understand the difference between concurrency and parallelism.\nAs Rob Pyke(one of the creators of GoLang) stated:â€œ Concurrency is about ğğğšğ¥ğ¢ğ§ğ  ğ°ğ¢ğ­ğ¡ lots of things at once. Parallelism is about ğğ¨ğ¢ğ§ğ  lots of things at once.\u0026quot; This distinction emphasizes that concurrency is more about the ğğğ¬ğ¢ğ ğ§ of a program, while parallelism is about the ğğ±ğğœğ®ğ­ğ¢ğ¨ğ§.\nConcurrency is about dealing with multiple things at once. It involves structuring a program to handle multiple tasks simultaneously, where the tasks can start, run, and complete in overlapping time periods, but not necessarily at the same instant.\nConcurrency is about the composition of independently executing processes and describes a program\u0026rsquo;s ability to manage multiple tasks by making progress on them without necessarily completing one before it starts another.\nParallelism, on the other hand, refers to the simultaneous execution of multiple computations. It is the technique of running two or more tasks or computations at the same time, utilizing multiple processors or cores within a computer to perform several operations concurrently. Parallelism requires hardware with multiple processing units, and its primary goal is to increase the throughput and computational speed of a system.\nIn practical terms, concurrency enables a program to remain responsive to input, perform background tasks, and handle multiple operations in a seemingly simultaneous manner, even on a single-core processor. It\u0026rsquo;s particularly useful in I/O-bound and high-latency operations where programs need to wait for external events, such as file, network, or user interactions.\nParallelism, with its ability to perform multiple operations at the same time, is crucial in CPU-bound tasks where computational speed and throughput are the bottlenecks. Applications that require heavy mathematical computations, data analysis, image processing, and real-time processing can significantly benefit from parallel execution.\n"},{"id":23,"href":"/docs/linux/system/linux-file-permissions/","title":"æ–‡ä»¶æƒé™è¯´æ˜","section":"Linuxç³»ç»Ÿ","content":"\n"},{"id":24,"href":"/docs/monitor/fantastic-four-of-system-design/","title":"ç³»ç»Ÿè®¾è®¡çš„4å¤§å…³é”®","section":"è¿ç»´","content":"\nWho are the Fantastic Four of System Design?\nScalability, Availability, Reliability, and Performance.\nThey are the most critical components to crafting successful software systems.\nLetâ€™s look at each of them with implementation techniques:\n1 - Scalability Scalability ensures that your application can handle more load without compromising performance.\n2 - Availability Availability makes sure that your application is always ready to serve the users and downtime is minimal.\n3 - Reliability Reliability is about building software that consistently delivers correct results.\n4 - Performance Performance is the ability of a system to carry out its tasks at an expected rate under peak load using available resources.\n"},{"id":25,"href":"/docs/network/https-handshake/","title":"HTTPSè¿æ¥å»ºç«‹è¿‡ç¨‹","section":"ç½‘ç»œ","content":"\n"},{"id":26,"href":"/docs/security/session-vs-jwt/","title":"Sessionå’ŒJWTçš„å¯¹æ¯”","section":"å®‰å…¨","content":"\nWhatâ€™s the difference between Session-based authentication and JWTs?\nHereâ€™s a simple breakdown for both approaches:\nSession-Based Authentication\nIn this approach, you store the session information in a database or session store and hand over a session ID to the user.\nThink of it like a passenger getting just the Ticket ID of their flight while all other details are stored in the airlineâ€™s database.\nHereâ€™s how it works:\n1 - The user makes a login request and the frontend app sends the request to the backend server.\n2 - The backend creates a session using a secret key and stores the data in session storage.\n3 - The server sends a cookie back to the client with the unique session ID.\n4 - The user makes a new request and the browser sends the session ID along with the request.\n5 - The server authenticates the user using the session ID.\nJWT-Based Authentication\nIn the JWT-based approach, you donâ€™t store the session information in the session store.\nThe entire information is available within the token.\nThink of it like getting the flight ticket along with all the details available on the ticket but encoded.\nHereâ€™s how it works:\n1 - The user makes a login request and it goes to the backend server.\n2 - The server verifies the credentials and issues a JWT. The JWT is signed using a private key and no session storage is involved.\n3 - The JWT is passed to the client, either as a cookie or in the response body. Both approaches have their pros and cons but weâ€™ve gone with the cookie approach.\n4 - For every subsequent request, the browser sends the cookie with the JWT.\n5 - The server verifies the JWT using the secret private key and extracts the user info.\n"},{"id":27,"href":"/docs/code/theory/design-effective-and-safe-apis/","title":"ç¼–å†™å‡ºå®‰å…¨æœ‰æ•ˆçš„API","section":"ç†è®º","content":"\nNote that API design is not just URL path design. Most of the time, we need to choose the proper resource names, identifiers, and path patterns. It is equally important to design proper HTTP header fields or to design effective rate-limiting rules within the API gateway.\n"},{"id":28,"href":"/docs/network/how-https-works/","title":"HTTPSæ˜¯å¦‚ä½•å·¥ä½œçš„","section":"ç½‘ç»œ","content":"\nHTTPS: Safeguards your data from eavesdroppers and breaches. Understand how encryption and digital certificates create an impregnable shield.\nSSL Handshake: Behind the Scenes â€” Witness the cryptographic protocols that establish a secure connection. Experience the intricate exchange of keys and negotiation.\nSecure Data Transmission: Navigating the Tunnel â€” Journey through the encrypted tunnel forged by HTTPS. Learn how your information travels while shielded from cyber threats.\nHTML\u0026rsquo;s Role: Peek into HTML\u0026rsquo;s role in structuring the web. Uncover how hyperlinks and content come together seamlessly. And why is it called HYPER TEXT.\n"},{"id":29,"href":"/docs/code/theory/top-9-system-integrations/","title":"REST API vs GraphQL","section":"ç†è®º","content":"\nREST API Vs. GraphQL When it comes to API design, REST and GraphQL each have their own strengths and weaknesses.\nREST - Uses standard HTTP methods like GET, POST, PUT, DELETE for CRUD operations. - Works well when you need simple, uniform interfaces between separate services/applications. - Caching strategies are straightforward to implement. - The downside is it may require multiple roundtrips to assemble related data from separate endpoints.\nGraphQL - Provides a single endpoint for clients to query for precisely the data they need. - Clients specify the exact fields required in nested queries, and the server returns optimized payloads containing just those fields. - Supports Mutations for modifying data and Subscriptions for real-time notifications. - Great for aggregating data from multiple sources and works well with rapidly evolving frontend requirements. - However, it shifts complexity to the client side and can allow abusive queries if not properly safeguarded - Caching strategies can be more complicated than REST.\nThe best choice between REST and GraphQL depends on the specific requirements of the application and development team. GraphQL is a good fit for complex or frequently changing frontend needs, while REST suits applications where simple and consistent contracts are preferred.\n"},{"id":30,"href":"/docs/code/theory/rest-api-vs-graphql/","title":"æ•°æ®é€šä¿¡çš„9ç§æ¶æ„æ¨¡å¼","section":"ç†è®º","content":"\nTop 9 Architectural Patterns for Data and Communication Flow\nğŸ”¹ Peer-to-Peer The Peer-to-Peer pattern involves direct communication between two components without the need for a central coordinator.\nğŸ”¹ API Gateway An API Gateway acts as a single entry point for all client requests to the backend services of an application.\nğŸ”¹ Pub-Sub The Pub-Sub pattern decouples the producers of messages (publishers) from the consumers of messages (subscribers) through a message broker.\nğŸ”¹ Request-Response This is one of the most fundamental integration patterns, where a client sends a request to a server and waits for a response.\nğŸ”¹ Event Sourcing Event Sourcing involves storing the state changes of an application as a sequence of events.\nğŸ”¹ ETL ETL is a data integration pattern used to gather data from multiple sources, transform it into a structured format, and load it into a destination database.\nğŸ”¹ Batching Batching involves accumulating data over a period or until a certain threshold is met before processing it as a single group.\nğŸ”¹ Streaming Processing Streaming Processing allows for the continuous ingestion, processing, and analysis of data streams in real-time.\nğŸ”¹ Orchestration Orchestration involves a central coordinator (an orchestrator) managing the interactions between distributed components or services to achieve a workflow or business process.\n"},{"id":31,"href":"/docs/microservice/develop/microservice-best-practices/","title":"å¾®æœåŠ¡æœ€ä½³å®è·µ","section":"å¾®æœåŠ¡å¼€å‘","content":"\n"}]